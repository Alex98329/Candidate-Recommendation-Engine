# -*- coding: utf-8 -*-
"""app_cv

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1rYSHBe2rShxWGNrn6OAGh5Wk1Vgaw0ZE
"""

"""Libraries"""

import streamlit as st
from sentence_transformers import SentenceTransformer, util
import openai
import os
import tempfile

# OpenAI (optional bonus feature)
openai.api_key = st.secrets.get("OPENAI_API_KEY", os.getenv("OPENAI_API_KEY"))

# Load embedding model
model = SentenceTransformer('all-MiniLM-L6-v2')

# App UI
st.title("Candidate Recommendation Engine")
st.markdown("Upload resumes and input a job description. Get the top-matching candidates.")

# Job description input
job_description = st.text_area("Job Description", height=200)

# Resume file upload
uploaded_files = st.file_uploader("Upload Candidate Resumes (TXT or PDF)", type=["txt", "pdf"], accept_multiple_files=True)

# Optional: max candidates to return
top_k = st.slider("Show Top K Candidates", min_value=1, max_value=10, value=5)

# Helper: extract text from file
def extract_text(file):
    if file.type == "application/pdf":
        from PyPDF2 import PdfReader
        pdf = PdfReader(file)
        return "\n".join([page.extract_text() or "" for page in pdf.pages])
    else:
        return file.read().decode("utf-8", errors="ignore")


# Generate summary with OpenAI
def generate_summary(job, resume):
    try:
        response = openai.ChatCompletion.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": "You're a technical recruiter."},
                {"role": "user", "content": f"Job: {job}\nResume: {resume}\nWhy is this person a good fit?"}
            ]
        )
        return response['choices'][0]['message']['content']
    except Exception as e:
        return f"Summary not generated: {e}"

# Run comparison
if st.button("Find Best Candidates") and job_description and uploaded_files:
    job_embedding = model.encode(job_description, convert_to_tensor=True)
    results = []

    for file in uploaded_files:
        resume_text = extract_text(file)
        resume_embedding = model.encode(resume_text, convert_to_tensor=True)
        similarity = util.pytorch_cos_sim(job_embedding, resume_embedding).item()

        summary = generate_summary(job_description, resume_text[:2000]) if openai.api_key else "—"

        results.append({
            "name": file.name,
            "score": round(similarity * 100, 2),
            "summary": summary
        })

    sorted_results = sorted(results, key=lambda x: x["score"], reverse=True)[:top_k]

    st.subheader("Top Matches")
    for res in sorted_results:
        st.markdown(f"**{res['name']}** — Similarity: `{res['score']}%`")
        if openai.api_key:
            with st.expander("Why this candidate?"):
                st.markdown(res['summary'])
